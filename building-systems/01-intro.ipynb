{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_module import getOpenAi\n",
    "openai = getOpenAi()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "      'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "      'completion_tokens':response['usage']['completion_tokens'],\n",
    "      'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_completion(\"What is the capital of France?\")\n",
    "# print(response)\n",
    "\n",
    "# response = get_completion(\"Reverse the letter in popsicle\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Grown in the garden, a joyful forage.\n",
      "With a smile so wide, from top to bottom,\n",
      "It brings happiness, oh how it blossoms!\n",
      "\n",
      "In the soil it grew, with love and care,\n",
      "Nurtured by sunshine, fresh air to share.\n",
      "Its leaves so green, reaching up so high,\n",
      "A happy carrot, oh my, oh my!\n",
      "\n",
      "With a crunch and a munch, it's oh so tasty,\n",
      "Filled with vitamins, oh so hasty.\n",
      "A healthy snack, a delight to eat,\n",
      "The happy carrot, oh so sweet!\n",
      "\n",
      "So let's celebrate this veggie delight,\n",
      "With every bite, a happy sight.\n",
      "For the happy carrot, we give a cheer,\n",
      "A joyful veggie, oh so dear!\n",
      "{'prompt_tokens': 37, 'completion_tokens': 160, 'total_tokens': 197}\n"
     ]
    }
   ],
   "source": [
    "# # messages =  [  \n",
    "# {'role':'system', 'content':\"\"\"You are an assistant who\\\n",
    "#  responds in the style of a car salesman.\"\"\"},    \n",
    "# {'role':'user', 'content':\"\"\"Write me a very short sales-pitch about a Honda Civic\"\"\"},  \n",
    "# ] \n",
    "# response = get_completion_from_messages(messages, temperature=1)\n",
    "# print(response)\n",
    "\n",
    "# # length\n",
    "# messages =  [  \n",
    "# {'role':'system',\n",
    "#  'content':'All your responses must be one sentence long.'},    \n",
    "# {'role':'user',\n",
    "#  'content':'write me a story about a happy carrot'},  \n",
    "# ] \n",
    "# response = get_completion_from_messages(messages, temperature =1)\n",
    "# print(response)\n",
    "\n",
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\ \n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "\n",
    "print(response)\n",
    "print(token_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
